{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ZhffDCLaWM",
        "outputId": "58b8bce9-0d78-41c3-fae1-9eea32f6c233"
      },
      "outputs": [],
      "source": [
        "project_name = 'inno_hack'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b11d3144-9f61-40b4-86df-9d2d4303a523"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from importlib import reload\n",
        "import sys\n",
        "from os import path\n",
        "\n",
        "sys.path.append('/home/greg/Personal/hackaton/rolling_drones_1/custom_modules')\n",
        "import my_sklearn_transformers as trsfm\n",
        "reload(trsfm)\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "path_to_data_dir = lambda x: path.join('/home/greg/Personal/hackaton/rolling_drones_1/ml/', *(x if isinstance(x, str) is False else [x]))\n",
        "path_to_cp_dir = lambda x: path.join('/home/greg/Personal/hackaton/rolling_drones_1/models/', *(x if isinstance(x, str) is False else [x]))\n",
        "path_to_pipeline_dir = lambda x: path.join('/home/greg/Personal/hackaton/rolling_drones_1/pipelines/', *(x if isinstance(x, str) is False else [x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S11w9aqN2OCJ"
      },
      "outputs": [],
      "source": [
        "U = pd.read_csv(path_to_data_dir('company_and_its_investor.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "BX7r89vN2N3V",
        "outputId": "05b5f7f9-3464-4257-e235-acde9524274b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>inn__investor</th>\n",
              "      <th>name__investor</th>\n",
              "      <th>type__investor</th>\n",
              "      <th>startup_stage__investor</th>\n",
              "      <th>market__investor</th>\n",
              "      <th>services__investor</th>\n",
              "      <th>technologies__investor</th>\n",
              "      <th>type_of_ownership__investor</th>\n",
              "      <th>investment_round__investor</th>\n",
              "      <th>investition_from_dol__investor</th>\n",
              "      <th>investition_to_dol__investor</th>\n",
              "      <th>tech_focus__investor</th>\n",
              "      <th>fund_total_rub__investor</th>\n",
              "      <th>fund_total_dol__investor</th>\n",
              "      <th>num_of_investments__investor</th>\n",
              "      <th>num_of_exits__investor</th>\n",
              "      <th>geography__investor</th>\n",
              "      <th>study_format__investor</th>\n",
              "      <th>num_of_people_in_company_from__investor</th>\n",
              "      <th>num_of_people_in_company_to__investor</th>\n",
              "      <th>num_of_participants__investor</th>\n",
              "      <th>okved_main__investor</th>\n",
              "      <th>okved_secondary__investor</th>\n",
              "      <th>corp_stage__investor</th>\n",
              "      <th>business_model__investor</th>\n",
              "      <th>monetary_support__investor</th>\n",
              "      <th>inn__company</th>\n",
              "      <th>name__company</th>\n",
              "      <th>got_support_from__company</th>\n",
              "      <th>did_get_support__company</th>\n",
              "      <th>service__company</th>\n",
              "      <th>foundation_date__company</th>\n",
              "      <th>tech_focus__company</th>\n",
              "      <th>stage_of_development__company</th>\n",
              "      <th>market__company</th>\n",
              "      <th>technology__company</th>\n",
              "      <th>business_model__company</th>\n",
              "      <th>main_okved__company</th>\n",
              "      <th>okved_secondary__company</th>\n",
              "      <th>msp_category__company</th>\n",
              "      <th>is_export__company</th>\n",
              "      <th>inno_cluster_member__company</th>\n",
              "      <th>skolcovo_member__company</th>\n",
              "      <th>is_inno_company__company</th>\n",
              "      <th>is_startup__company</th>\n",
              "      <th>current_profit__company</th>\n",
              "      <th>current_profit_tax__company</th>\n",
              "      <th>current_revenue__company</th>\n",
              "      <th>type__company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7703638456</td>\n",
              "      <td>da vinci capital</td>\n",
              "      <td>VentureFund</td>\n",
              "      <td>['ранний рост', 'расширение']</td>\n",
              "      <td>['cybersecurity', 'transport &amp; logistics', 'bu...</td>\n",
              "      <td>['инвестиции']</td>\n",
              "      <td>['ar/vr', 'big data', 'блокчейн', 'интернет ве...</td>\n",
              "      <td>частный</td>\n",
              "      <td>['раунд а', 'раунд в', 'раунд с+']</td>\n",
              "      <td>1000000.0</td>\n",
              "      <td>50000000.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7704794345</td>\n",
              "      <td>ооо \"геттакси рус\"</td>\n",
              "      <td>карта инновационных решений</td>\n",
              "      <td>да</td>\n",
              "      <td>добавлено - карта инновационных решений</td>\n",
              "      <td>2011-11-03</td>\n",
              "      <td>['транспорт и логистика']</td>\n",
              "      <td>расширение</td>\n",
              "      <td>['transport &amp; logistics']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['b2c']</td>\n",
              "      <td>62.09</td>\n",
              "      <td>['82.99', '46.19', '63.11.1', '47.91.2', '69.2...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>нет</td>\n",
              "      <td>да</td>\n",
              "      <td>нет</td>\n",
              "      <td>да</td>\n",
              "      <td>нет</td>\n",
              "      <td>-23.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>1507.0</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7728461088</td>\n",
              "      <td>new industry ventures</td>\n",
              "      <td>VentureFund</td>\n",
              "      <td>['ранний рост', 'расширение', 'посевная']</td>\n",
              "      <td>['cleantech']</td>\n",
              "      <td>['инвестиции']</td>\n",
              "      <td>['3d моделирование', 'big data', 'интернет вещ...</td>\n",
              "      <td>частный</td>\n",
              "      <td>['seed', 'раунд а', 'раунд в']</td>\n",
              "      <td>500000.0</td>\n",
              "      <td>3000000.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7714762021</td>\n",
              "      <td>ооо \"скайер ит\"</td>\n",
              "      <td>московский акселератор</td>\n",
              "      <td>нет</td>\n",
              "      <td>московский акселератор</td>\n",
              "      <td>2008-12-23</td>\n",
              "      <td>['недвижимость и строительство']</td>\n",
              "      <td>ранний рост</td>\n",
              "      <td>['proptech']</td>\n",
              "      <td>['беспилотники']</td>\n",
              "      <td>['b2b']</td>\n",
              "      <td>72.19</td>\n",
              "      <td>['62.09', '85.42', '62.02', '63.11.1', '30.30....</td>\n",
              "      <td>юл микро</td>\n",
              "      <td>нет</td>\n",
              "      <td>да</td>\n",
              "      <td>да</td>\n",
              "      <td>да</td>\n",
              "      <td>нет</td>\n",
              "      <td>-16450.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19127.0</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7728461088</td>\n",
              "      <td>new industry ventures</td>\n",
              "      <td>VentureFund</td>\n",
              "      <td>['ранний рост', 'расширение', 'посевная']</td>\n",
              "      <td>['cleantech']</td>\n",
              "      <td>['инвестиции']</td>\n",
              "      <td>['3d моделирование', 'big data', 'интернет вещ...</td>\n",
              "      <td>частный</td>\n",
              "      <td>['seed', 'раунд а', 'раунд в']</td>\n",
              "      <td>500000.0</td>\n",
              "      <td>3000000.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7714762021</td>\n",
              "      <td>ооо \"радуга\"</td>\n",
              "      <td>карта инновационных решений</td>\n",
              "      <td>да</td>\n",
              "      <td>добавлено - карта инновационных решений</td>\n",
              "      <td>2008-12-23</td>\n",
              "      <td>['недвижимость и строительство']</td>\n",
              "      <td>ранний рост</td>\n",
              "      <td>['proptech']</td>\n",
              "      <td>['беспилотники']</td>\n",
              "      <td>['b2b']</td>\n",
              "      <td>72.19</td>\n",
              "      <td>['62.09', '85.42', '62.02', '63.11.1', '30.30....</td>\n",
              "      <td>юл микро</td>\n",
              "      <td>нет</td>\n",
              "      <td>да</td>\n",
              "      <td>да</td>\n",
              "      <td>да</td>\n",
              "      <td>нет</td>\n",
              "      <td>-16450.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19127.0</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  inn__investor         name__investor type__investor  \\\n",
              "0           0     7703638456       da vinci capital    VentureFund   \n",
              "1           1     7728461088  new industry ventures    VentureFund   \n",
              "2           2     7728461088  new industry ventures    VentureFund   \n",
              "\n",
              "                     startup_stage__investor  \\\n",
              "0              ['ранний рост', 'расширение']   \n",
              "1  ['ранний рост', 'расширение', 'посевная']   \n",
              "2  ['ранний рост', 'расширение', 'посевная']   \n",
              "\n",
              "                                    market__investor services__investor  \\\n",
              "0  ['cybersecurity', 'transport & logistics', 'bu...     ['инвестиции']   \n",
              "1                                      ['cleantech']     ['инвестиции']   \n",
              "2                                      ['cleantech']     ['инвестиции']   \n",
              "\n",
              "                              technologies__investor  \\\n",
              "0  ['ar/vr', 'big data', 'блокчейн', 'интернет ве...   \n",
              "1  ['3d моделирование', 'big data', 'интернет вещ...   \n",
              "2  ['3d моделирование', 'big data', 'интернет вещ...   \n",
              "\n",
              "  type_of_ownership__investor          investment_round__investor  \\\n",
              "0                     частный  ['раунд а', 'раунд в', 'раунд с+']   \n",
              "1                     частный      ['seed', 'раунд а', 'раунд в']   \n",
              "2                     частный      ['seed', 'раунд а', 'раунд в']   \n",
              "\n",
              "   investition_from_dol__investor  investition_to_dol__investor  \\\n",
              "0                       1000000.0                    50000000.0   \n",
              "1                        500000.0                     3000000.0   \n",
              "2                        500000.0                     3000000.0   \n",
              "\n",
              "  tech_focus__investor  fund_total_rub__investor  fund_total_dol__investor  \\\n",
              "0                   []                   25000.0                     397.0   \n",
              "1                   []                    4000.0                      62.0   \n",
              "2                   []                    4000.0                      62.0   \n",
              "\n",
              "   num_of_investments__investor  num_of_exits__investor geography__investor  \\\n",
              "0                          17.0                     2.0                 NaN   \n",
              "1                           1.0                     0.0                 NaN   \n",
              "2                           1.0                     0.0                 NaN   \n",
              "\n",
              "  study_format__investor  num_of_people_in_company_from__investor  \\\n",
              "0                    NaN                                      NaN   \n",
              "1                    NaN                                      NaN   \n",
              "2                    NaN                                      NaN   \n",
              "\n",
              "   num_of_people_in_company_to__investor  num_of_participants__investor  \\\n",
              "0                                    NaN                            NaN   \n",
              "1                                    NaN                            NaN   \n",
              "2                                    NaN                            NaN   \n",
              "\n",
              "   okved_main__investor  okved_secondary__investor  corp_stage__investor  \\\n",
              "0                   NaN                        NaN                   NaN   \n",
              "1                   NaN                        NaN                   NaN   \n",
              "2                   NaN                        NaN                   NaN   \n",
              "\n",
              "   business_model__investor monetary_support__investor  inn__company  \\\n",
              "0                       NaN                        NaN    7704794345   \n",
              "1                       NaN                        NaN    7714762021   \n",
              "2                       NaN                        NaN    7714762021   \n",
              "\n",
              "        name__company    got_support_from__company did_get_support__company  \\\n",
              "0  ооо \"геттакси рус\"  карта инновационных решений                       да   \n",
              "1     ооо \"скайер ит\"       московский акселератор                      нет   \n",
              "2        ооо \"радуга\"  карта инновационных решений                       да   \n",
              "\n",
              "                          service__company foundation_date__company  \\\n",
              "0  добавлено - карта инновационных решений               2011-11-03   \n",
              "1                   московский акселератор               2008-12-23   \n",
              "2  добавлено - карта инновационных решений               2008-12-23   \n",
              "\n",
              "                tech_focus__company stage_of_development__company  \\\n",
              "0         ['транспорт и логистика']                    расширение   \n",
              "1  ['недвижимость и строительство']                   ранний рост   \n",
              "2  ['недвижимость и строительство']                   ранний рост   \n",
              "\n",
              "             market__company technology__company business_model__company  \\\n",
              "0  ['transport & logistics']                  []                 ['b2c']   \n",
              "1               ['proptech']    ['беспилотники']                 ['b2b']   \n",
              "2               ['proptech']    ['беспилотники']                 ['b2b']   \n",
              "\n",
              "  main_okved__company                           okved_secondary__company  \\\n",
              "0               62.09  ['82.99', '46.19', '63.11.1', '47.91.2', '69.2...   \n",
              "1               72.19  ['62.09', '85.42', '62.02', '63.11.1', '30.30....   \n",
              "2               72.19  ['62.09', '85.42', '62.02', '63.11.1', '30.30....   \n",
              "\n",
              "  msp_category__company is_export__company inno_cluster_member__company  \\\n",
              "0                   NaN                нет                           да   \n",
              "1              юл микро                нет                           да   \n",
              "2              юл микро                нет                           да   \n",
              "\n",
              "  skolcovo_member__company is_inno_company__company is_startup__company  \\\n",
              "0                      нет                       да                 нет   \n",
              "1                       да                       да                 нет   \n",
              "2                       да                       да                 нет   \n",
              "\n",
              "   current_profit__company  current_profit_tax__company  \\\n",
              "0                    -23.0                        -15.0   \n",
              "1                 -16450.0                          0.0   \n",
              "2                 -16450.0                          0.0   \n",
              "\n",
              "   current_revenue__company type__company  \n",
              "0                    1507.0       Company  \n",
              "1                   19127.0       Company  \n",
              "2                   19127.0       Company  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "U.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "STaE3QeV7jQE"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "def try_load_list(val):\n",
        "    try:\n",
        "        res = ast.literal_eval(val)\n",
        "        if isinstance(res, list):\n",
        "            return res\n",
        "        else:\n",
        "            return []\n",
        "    except Exception as e:\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jfu1ZRRA1TNH"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_union, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer, FunctionTransformer, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "onehot_company = ['stage_of_development__company', 'main_okved__company', 'msp_category__company', 'is_export__company', 'inno_cluster_member__company', 'skolcovo_member__company',\n",
        "                  'is_inno_company__company', 'is_startup__company']\n",
        "multilabel_company = ['tech_focus__company', 'market__company', 'technology__company', 'business_model__company', 'okved_secondary__company']\n",
        "\n",
        "\n",
        "num_investor = ['investition_from_dol__investor', 'investition_to_dol__investor', 'fund_total_rub__investor', \n",
        "                'fund_total_dol__investor', 'num_of_investments__investor', 'num_of_exits__investor']\n",
        "onehot_investor = ['type_of_ownership__investor']\n",
        "multilabel_investor = ['startup_stage__investor', 'market__investor', 'services__investor', 'technologies__investor', 'investment_round__investor', 'tech_focus__investor']\n",
        "\n",
        "def map_lists(x):\n",
        "    return np.array([try_load_list(i) for i in x], dtype=object)\n",
        "\n",
        "preprocessor_X = make_union(\n",
        "    make_pipeline(\n",
        "        trsfm.DfSelector(onehot_company),\n",
        "        SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=''),\n",
        "        OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "    ),\n",
        "    *([make_pipeline(\n",
        "        trsfm.DfSelector([col]),\n",
        "        FunctionTransformer(np.squeeze),\n",
        "        FunctionTransformer(map_lists),\n",
        "        # FunctionTransformer(print),\n",
        "        trsfm.MultilabelEncoder()\n",
        "    ) for col in multilabel_company])\n",
        ")\n",
        "\n",
        "preprocessor_Y = make_union(\n",
        "    make_pipeline(\n",
        "        trsfm.DfSelector(onehot_investor),\n",
        "        SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=''),\n",
        "        OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "    ),\n",
        "    make_pipeline(\n",
        "        trsfm.DfSelector(num_investor),\n",
        "        SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0),\n",
        "        MinMaxScaler()\n",
        "    ),\n",
        "    *([make_pipeline(\n",
        "        trsfm.DfSelector([col]),\n",
        "        FunctionTransformer(np.squeeze),\n",
        "        FunctionTransformer(map_lists),\n",
        "        trsfm.MultilabelEncoder()\n",
        "    ) for col in multilabel_investor])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IjdweWcZ4mp4",
        "outputId": "5823396c-cb3a-45ec-8bbb-b3bb82125e76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0.24.2'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CATQvO0QNEO0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1)\n",
        "for train, test in sss.split(U, U['type_of_ownership__investor'].fillna('')):\n",
        "    train_idx, test_idx = train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4925cfa2-fec4-4af2-a18f-1e8f11d4eb89",
        "outputId": "deddb191-b44b-4e79-b1fb-7853bcc4d50d"
      },
      "outputs": [],
      "source": [
        "X_tr = preprocessor_X.fit_transform(U.iloc[train_idx])\n",
        "X_te = preprocessor_X.transform(U.iloc[test_idx])\n",
        "y_tr = preprocessor_Y.fit_transform(U.iloc[train_idx])\n",
        "y_te = preprocessor_Y.transform(U.iloc[test_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NJKQRtAMaK7",
        "outputId": "14f7dfdf-379a-4fca-a096-62c3ed240085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/home/greg/Personal/hackaton/rolling_drones_1/pipelines/fund_classifier_preprocessor_Y.joblib']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump\n",
        "\n",
        "dump(preprocessor_X, path_to_pipeline_dir('fund_classifier_preprocessor_X.joblib'))\n",
        "dump(preprocessor_Y, path_to_pipeline_dir('fund_classifier_preprocessor_Y.joblib'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yHtV9tbFCGZ",
        "outputId": "652a6844-8f56-46a6-b47b-687f1baedf69"
      },
      "outputs": [],
      "source": [
        "unique_fund = U.drop_duplicates(subset=['name__investor'])\n",
        "investors_space = preprocessor_Y.transform(unique_fund)\n",
        "investors_space_name = unique_fund['name__investor'].values\n",
        "fund_name_te = U.iloc[test_idx]['name__investor'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CtLeaFz7uKq",
        "outputId": "26baa753-d056-4077-e642-945e45bc7fdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(59, 77)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "investors_space.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj3e0LVWIcuh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ffdde2-d8e4-4772-b1ab-fd7803c3f592",
        "outputId": "73ade923-38b4-44f2-89e5-cd2ec570302b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((362, 571), (41, 571), (362, 77), (41, 77), 0.0, 1.0)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tr.shape, X_te.shape, y_tr.shape, y_te.shape, y_tr.min(), y_tr.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMJFqyJT7tBe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ8QlEnzCehH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T-wEvzFhJ53"
      },
      "source": [
        "# Модель\n",
        "\n",
        "Генерация предсказания построена так:\n",
        "Данные о компании, для которой нужно получить рекомендацию, переводяться в n-мерный вектор, который при помощи 2-слойной модели проецируется в m-мерное пространство сервисов. Далее сравнивается L2 норм расстояния от проекции вектора компании до векторов сервисов, и по данным расстояниям сервисы сортируются в порядке убывания релевантности.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ioApyMCelp",
        "outputId": "a7c55153-0878-475d-d6a9-3482f88144a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               146432    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 77)                19789     \n",
            "=================================================================\n",
            "Total params: 166,221\n",
            "Trainable params: 166,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-04 00:43:01.211012: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "2021-11-04 00:43:01.225749: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2099940000 Hz\n",
            "2021-11-04 00:43:01.226050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5621f64ab330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-04 00:43:01.226068: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-04 00:43:01.227897: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "es_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0.001, patience=100, verbose=0,\n",
        "    mode='auto', baseline=None, restore_best_weights=True\n",
        ")\n",
        "\n",
        "loss = MeanSquaredError()\n",
        "\n",
        "l_size = 256\n",
        "dropo = 0.5\n",
        "\n",
        "model = tf.keras.Sequential(layers=[\n",
        "    layers.Dense(l_size, input_shape=(X_tr.shape[1],), activation='sigmoid'),\n",
        "    layers.Dropout(dropo),\n",
        "    layers.Dense(y_tr.shape[1], activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWLSj_J8ChqX",
        "outputId": "90a05a39-b873-4733-a288-877d4e0ead77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2349 - val_loss: 0.1664\n",
            "Epoch 2/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1825 - val_loss: 0.1568\n",
            "Epoch 3/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1769 - val_loss: 0.1536\n",
            "Epoch 4/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1744 - val_loss: 0.1514\n",
            "Epoch 5/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1699 - val_loss: 0.1497\n",
            "Epoch 6/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1687 - val_loss: 0.1486\n",
            "Epoch 7/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1657 - val_loss: 0.1467\n",
            "Epoch 8/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1640 - val_loss: 0.1451\n",
            "Epoch 9/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1626 - val_loss: 0.1434\n",
            "Epoch 10/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1591 - val_loss: 0.1420\n",
            "Epoch 11/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1560 - val_loss: 0.1404\n",
            "Epoch 12/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1527 - val_loss: 0.1383\n",
            "Epoch 13/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1497 - val_loss: 0.1368\n",
            "Epoch 14/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1471 - val_loss: 0.1349\n",
            "Epoch 15/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1459 - val_loss: 0.1331\n",
            "Epoch 16/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1425 - val_loss: 0.1308\n",
            "Epoch 17/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1402 - val_loss: 0.1290\n",
            "Epoch 18/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.1348 - val_loss: 0.1271\n",
            "Epoch 19/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1341 - val_loss: 0.1252\n",
            "Epoch 20/3000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1316 - val_loss: 0.1237\n",
            "Epoch 21/3000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1308 - val_loss: 0.1215\n",
            "Epoch 22/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1272 - val_loss: 0.1198\n",
            "Epoch 23/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1256 - val_loss: 0.1184\n",
            "Epoch 24/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1248 - val_loss: 0.1171\n",
            "Epoch 25/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1226 - val_loss: 0.1159\n",
            "Epoch 26/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1203 - val_loss: 0.1146\n",
            "Epoch 27/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1197 - val_loss: 0.1136\n",
            "Epoch 28/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1182 - val_loss: 0.1119\n",
            "Epoch 29/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1159 - val_loss: 0.1110\n",
            "Epoch 30/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1156 - val_loss: 0.1101\n",
            "Epoch 31/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1140 - val_loss: 0.1098\n",
            "Epoch 32/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1112 - val_loss: 0.1087\n",
            "Epoch 33/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1127 - val_loss: 0.1087\n",
            "Epoch 34/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1094 - val_loss: 0.1081\n",
            "Epoch 35/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1117 - val_loss: 0.1076\n",
            "Epoch 36/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1084 - val_loss: 0.1067\n",
            "Epoch 37/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.1077 - val_loss: 0.1059\n",
            "Epoch 38/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1083 - val_loss: 0.1051\n",
            "Epoch 39/3000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1053 - val_loss: 0.1052\n",
            "Epoch 40/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1058 - val_loss: 0.1053\n",
            "Epoch 41/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1031 - val_loss: 0.1036\n",
            "Epoch 42/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1046 - val_loss: 0.1040\n",
            "Epoch 43/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1031 - val_loss: 0.1027\n",
            "Epoch 44/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1040 - val_loss: 0.1021\n",
            "Epoch 45/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0998 - val_loss: 0.1013\n",
            "Epoch 46/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1008 - val_loss: 0.1009\n",
            "Epoch 47/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0998 - val_loss: 0.1005\n",
            "Epoch 48/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1015 - val_loss: 0.1005\n",
            "Epoch 49/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0993 - val_loss: 0.1003\n",
            "Epoch 50/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0984 - val_loss: 0.1000\n",
            "Epoch 51/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0989 - val_loss: 0.0994\n",
            "Epoch 52/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0960 - val_loss: 0.0992\n",
            "Epoch 53/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0954 - val_loss: 0.0988\n",
            "Epoch 54/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0960 - val_loss: 0.0980\n",
            "Epoch 55/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0953 - val_loss: 0.0984\n",
            "Epoch 56/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0956 - val_loss: 0.0989\n",
            "Epoch 57/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0966 - val_loss: 0.0984\n",
            "Epoch 58/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0935 - val_loss: 0.0982\n",
            "Epoch 59/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0959 - val_loss: 0.0980\n",
            "Epoch 60/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0946 - val_loss: 0.0986\n",
            "Epoch 61/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0941 - val_loss: 0.0982\n",
            "Epoch 62/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0928 - val_loss: 0.0986\n",
            "Epoch 63/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0937 - val_loss: 0.0986\n",
            "Epoch 64/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0909 - val_loss: 0.0982\n",
            "Epoch 65/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0922 - val_loss: 0.0976\n",
            "Epoch 66/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0933 - val_loss: 0.0976\n",
            "Epoch 67/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0887 - val_loss: 0.0972\n",
            "Epoch 68/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0915 - val_loss: 0.0976\n",
            "Epoch 69/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0923 - val_loss: 0.0970\n",
            "Epoch 70/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0901 - val_loss: 0.0966\n",
            "Epoch 71/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0894 - val_loss: 0.0972\n",
            "Epoch 72/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0900 - val_loss: 0.0971\n",
            "Epoch 73/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0887 - val_loss: 0.0967\n",
            "Epoch 74/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0887 - val_loss: 0.0966\n",
            "Epoch 75/3000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0882 - val_loss: 0.0964\n",
            "Epoch 76/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0891 - val_loss: 0.0958\n",
            "Epoch 77/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0903 - val_loss: 0.0956\n",
            "Epoch 78/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0885 - val_loss: 0.0959\n",
            "Epoch 79/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0867 - val_loss: 0.0955\n",
            "Epoch 80/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0855 - val_loss: 0.0958\n",
            "Epoch 81/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0866 - val_loss: 0.0958\n",
            "Epoch 82/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0858 - val_loss: 0.0962\n",
            "Epoch 83/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0859 - val_loss: 0.0960\n",
            "Epoch 84/3000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.0871 - val_loss: 0.0959\n",
            "Epoch 85/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0843 - val_loss: 0.0963\n",
            "Epoch 86/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0866 - val_loss: 0.0961\n",
            "Epoch 87/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0848 - val_loss: 0.0959\n",
            "Epoch 88/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0846 - val_loss: 0.0959\n",
            "Epoch 89/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0845 - val_loss: 0.0961\n",
            "Epoch 90/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0855 - val_loss: 0.0962\n",
            "Epoch 91/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0839 - val_loss: 0.0951\n",
            "Epoch 92/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0842 - val_loss: 0.0962\n",
            "Epoch 93/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0834 - val_loss: 0.0962\n",
            "Epoch 94/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0824 - val_loss: 0.0951\n",
            "Epoch 95/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0827 - val_loss: 0.0955\n",
            "Epoch 96/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0855 - val_loss: 0.0953\n",
            "Epoch 97/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0843 - val_loss: 0.0955\n",
            "Epoch 98/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0815 - val_loss: 0.0960\n",
            "Epoch 99/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0816 - val_loss: 0.0955\n",
            "Epoch 100/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0833 - val_loss: 0.0950\n",
            "Epoch 101/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0824 - val_loss: 0.0950\n",
            "Epoch 102/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0834 - val_loss: 0.0955\n",
            "Epoch 103/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0831 - val_loss: 0.0952\n",
            "Epoch 104/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0820 - val_loss: 0.0951\n",
            "Epoch 105/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0813 - val_loss: 0.0949\n",
            "Epoch 106/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0823 - val_loss: 0.0948\n",
            "Epoch 107/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0811 - val_loss: 0.0956\n",
            "Epoch 108/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0809 - val_loss: 0.0952\n",
            "Epoch 109/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0807 - val_loss: 0.0949\n",
            "Epoch 110/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0813 - val_loss: 0.0951\n",
            "Epoch 111/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0820 - val_loss: 0.0950\n",
            "Epoch 112/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0802 - val_loss: 0.0944\n",
            "Epoch 113/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0820 - val_loss: 0.0947\n",
            "Epoch 114/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0811 - val_loss: 0.0943\n",
            "Epoch 115/3000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0790 - val_loss: 0.0940\n",
            "Epoch 116/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0801 - val_loss: 0.0943\n",
            "Epoch 117/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0804 - val_loss: 0.0948\n",
            "Epoch 118/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0822 - val_loss: 0.0951\n",
            "Epoch 119/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0797 - val_loss: 0.0946\n",
            "Epoch 120/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0793 - val_loss: 0.0949\n",
            "Epoch 121/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0812 - val_loss: 0.0952\n",
            "Epoch 122/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0807 - val_loss: 0.0946\n",
            "Epoch 123/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0794 - val_loss: 0.0949\n",
            "Epoch 124/3000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0789 - val_loss: 0.0950\n",
            "Epoch 125/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0791 - val_loss: 0.0947\n",
            "Epoch 126/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0783 - val_loss: 0.0940\n",
            "Epoch 127/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0791 - val_loss: 0.0950\n",
            "Epoch 128/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0786 - val_loss: 0.0953\n",
            "Epoch 129/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0798 - val_loss: 0.0952\n",
            "Epoch 130/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0789 - val_loss: 0.0949\n",
            "Epoch 131/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0796 - val_loss: 0.0951\n",
            "Epoch 132/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0799 - val_loss: 0.0958\n",
            "Epoch 133/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0780 - val_loss: 0.0959\n",
            "Epoch 134/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0799 - val_loss: 0.0953\n",
            "Epoch 135/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0777 - val_loss: 0.0949\n",
            "Epoch 136/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0796 - val_loss: 0.0950\n",
            "Epoch 137/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0753 - val_loss: 0.0952\n",
            "Epoch 138/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0777 - val_loss: 0.0954\n",
            "Epoch 139/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0785 - val_loss: 0.0950\n",
            "Epoch 140/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0762 - val_loss: 0.0948\n",
            "Epoch 141/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0777 - val_loss: 0.0949\n",
            "Epoch 142/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0771 - val_loss: 0.0953\n",
            "Epoch 143/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0787 - val_loss: 0.0945\n",
            "Epoch 144/3000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0779 - val_loss: 0.0948\n",
            "Epoch 145/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0755 - val_loss: 0.0944\n",
            "Epoch 146/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0748 - val_loss: 0.0940\n",
            "Epoch 147/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0787 - val_loss: 0.0936\n",
            "Epoch 148/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0761 - val_loss: 0.0941\n",
            "Epoch 149/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0770 - val_loss: 0.0931\n",
            "Epoch 150/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0777 - val_loss: 0.0928\n",
            "Epoch 151/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0779 - val_loss: 0.0927\n",
            "Epoch 152/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0780 - val_loss: 0.0929\n",
            "Epoch 153/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0770 - val_loss: 0.0926\n",
            "Epoch 154/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0787 - val_loss: 0.0932\n",
            "Epoch 155/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0741 - val_loss: 0.0939\n",
            "Epoch 156/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0761 - val_loss: 0.0942\n",
            "Epoch 157/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0765 - val_loss: 0.0944\n",
            "Epoch 158/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0765 - val_loss: 0.0938\n",
            "Epoch 159/3000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0750 - val_loss: 0.0933\n",
            "Epoch 160/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0751 - val_loss: 0.0926\n",
            "Epoch 161/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0765 - val_loss: 0.0927\n",
            "Epoch 162/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0769 - val_loss: 0.0925\n",
            "Epoch 163/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0739 - val_loss: 0.0925\n",
            "Epoch 164/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0754 - val_loss: 0.0923\n",
            "Epoch 165/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0745 - val_loss: 0.0924\n",
            "Epoch 166/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0769 - val_loss: 0.0933\n",
            "Epoch 167/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0756 - val_loss: 0.0921\n",
            "Epoch 168/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0755 - val_loss: 0.0916\n",
            "Epoch 169/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0739 - val_loss: 0.0917\n",
            "Epoch 170/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0734 - val_loss: 0.0925\n",
            "Epoch 171/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0744 - val_loss: 0.0928\n",
            "Epoch 172/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0737 - val_loss: 0.0937\n",
            "Epoch 173/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0742 - val_loss: 0.0936\n",
            "Epoch 174/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0741 - val_loss: 0.0935\n",
            "Epoch 175/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0734 - val_loss: 0.0936\n",
            "Epoch 176/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0738 - val_loss: 0.0934\n",
            "Epoch 177/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0762 - val_loss: 0.0932\n",
            "Epoch 178/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0755 - val_loss: 0.0925\n",
            "Epoch 179/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0739 - val_loss: 0.0935\n",
            "Epoch 180/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0727 - val_loss: 0.0938\n",
            "Epoch 181/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0746 - val_loss: 0.0922\n",
            "Epoch 182/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0742 - val_loss: 0.0924\n",
            "Epoch 183/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0727 - val_loss: 0.0925\n",
            "Epoch 184/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0740 - val_loss: 0.0927\n",
            "Epoch 185/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0747 - val_loss: 0.0925\n",
            "Epoch 186/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0729 - val_loss: 0.0927\n",
            "Epoch 187/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0750 - val_loss: 0.0925\n",
            "Epoch 188/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0722 - val_loss: 0.0921\n",
            "Epoch 189/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0736 - val_loss: 0.0927\n",
            "Epoch 190/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0762 - val_loss: 0.0928\n",
            "Epoch 191/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0721 - val_loss: 0.0932\n",
            "Epoch 192/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0743 - val_loss: 0.0927\n",
            "Epoch 193/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0732 - val_loss: 0.0921\n",
            "Epoch 194/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0735 - val_loss: 0.0922\n",
            "Epoch 195/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0735 - val_loss: 0.0924\n",
            "Epoch 196/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0728 - val_loss: 0.0924\n",
            "Epoch 197/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0727 - val_loss: 0.0924\n",
            "Epoch 198/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0738 - val_loss: 0.0924\n",
            "Epoch 199/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0731 - val_loss: 0.0931\n",
            "Epoch 200/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0721 - val_loss: 0.0929\n",
            "Epoch 201/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0730 - val_loss: 0.0931\n",
            "Epoch 202/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0725 - val_loss: 0.0925\n",
            "Epoch 203/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0724 - val_loss: 0.0925\n",
            "Epoch 204/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0738 - val_loss: 0.0923\n",
            "Epoch 205/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0726 - val_loss: 0.0928\n",
            "Epoch 206/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0741 - val_loss: 0.0938\n",
            "Epoch 207/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0723 - val_loss: 0.0937\n",
            "Epoch 208/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0730 - val_loss: 0.0940\n",
            "Epoch 209/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0689 - val_loss: 0.0941\n",
            "Epoch 210/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0729 - val_loss: 0.0934\n",
            "Epoch 211/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0732 - val_loss: 0.0930\n",
            "Epoch 212/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0750 - val_loss: 0.0931\n",
            "Epoch 213/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0744 - val_loss: 0.0932\n",
            "Epoch 214/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0750 - val_loss: 0.0935\n",
            "Epoch 215/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0724 - val_loss: 0.0935\n",
            "Epoch 216/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0739 - val_loss: 0.0939\n",
            "Epoch 217/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0720 - val_loss: 0.0939\n",
            "Epoch 218/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0721 - val_loss: 0.0931\n",
            "Epoch 219/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0749 - val_loss: 0.0927\n",
            "Epoch 220/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0725 - val_loss: 0.0933\n",
            "Epoch 221/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0739 - val_loss: 0.0936\n",
            "Epoch 222/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0719 - val_loss: 0.0936\n",
            "Epoch 223/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0706 - val_loss: 0.0933\n",
            "Epoch 224/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0726 - val_loss: 0.0935\n",
            "Epoch 225/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0734 - val_loss: 0.0933\n",
            "Epoch 226/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0713 - val_loss: 0.0934\n",
            "Epoch 227/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0731 - val_loss: 0.0933\n",
            "Epoch 228/3000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.0724 - val_loss: 0.0929\n",
            "Epoch 229/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0712 - val_loss: 0.0929\n",
            "Epoch 230/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0713 - val_loss: 0.0932\n",
            "Epoch 231/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0712 - val_loss: 0.0934\n",
            "Epoch 232/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0721 - val_loss: 0.0929\n",
            "Epoch 233/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0716 - val_loss: 0.0925\n",
            "Epoch 234/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0726 - val_loss: 0.0921\n",
            "Epoch 235/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0718 - val_loss: 0.0921\n",
            "Epoch 236/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0718 - val_loss: 0.0923\n",
            "Epoch 237/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0715 - val_loss: 0.0923\n",
            "Epoch 238/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0717 - val_loss: 0.0928\n",
            "Epoch 239/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0705 - val_loss: 0.0922\n",
            "Epoch 240/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0720 - val_loss: 0.0924\n",
            "Epoch 241/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0720 - val_loss: 0.0926\n",
            "Epoch 242/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0707 - val_loss: 0.0925\n",
            "Epoch 243/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0709 - val_loss: 0.0924\n",
            "Epoch 244/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0694 - val_loss: 0.0924\n",
            "Epoch 245/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0703 - val_loss: 0.0922\n",
            "Epoch 246/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0718 - val_loss: 0.0919\n",
            "Epoch 247/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0700 - val_loss: 0.0921\n",
            "Epoch 248/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0714 - val_loss: 0.0921\n",
            "Epoch 249/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0721 - val_loss: 0.0921\n",
            "Epoch 250/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0706 - val_loss: 0.0922\n",
            "Epoch 251/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0720 - val_loss: 0.0919\n",
            "Epoch 252/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0703 - val_loss: 0.0921\n",
            "Epoch 253/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0710 - val_loss: 0.0918\n",
            "Epoch 254/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0701 - val_loss: 0.0916\n",
            "Epoch 255/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0709 - val_loss: 0.0914\n",
            "Epoch 256/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0696 - val_loss: 0.0917\n",
            "Epoch 257/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0713 - val_loss: 0.0918\n",
            "Epoch 258/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0706 - val_loss: 0.0920\n",
            "Epoch 259/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0707 - val_loss: 0.0914\n",
            "Epoch 260/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0713 - val_loss: 0.0913\n",
            "Epoch 261/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0699 - val_loss: 0.0919\n",
            "Epoch 262/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0716 - val_loss: 0.0923\n",
            "Epoch 263/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0699 - val_loss: 0.0924\n",
            "Epoch 264/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0717 - val_loss: 0.0925\n",
            "Epoch 265/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0706 - val_loss: 0.0926\n",
            "Epoch 266/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0705 - val_loss: 0.0922\n",
            "Epoch 267/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0709 - val_loss: 0.0920\n",
            "Epoch 268/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0717 - val_loss: 0.0919\n",
            "Epoch 269/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0711 - val_loss: 0.0922\n",
            "Epoch 270/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0700 - val_loss: 0.0929\n",
            "Epoch 271/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0705 - val_loss: 0.0930\n",
            "Epoch 272/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0682 - val_loss: 0.0933\n",
            "Epoch 273/3000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0713 - val_loss: 0.0934\n",
            "Epoch 274/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0684 - val_loss: 0.0931\n",
            "Epoch 275/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0713 - val_loss: 0.0930\n",
            "Epoch 276/3000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0701 - val_loss: 0.0929\n",
            "Epoch 277/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0706 - val_loss: 0.0928\n",
            "Epoch 278/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0707 - val_loss: 0.0928\n",
            "Epoch 279/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0697 - val_loss: 0.0926\n",
            "Epoch 280/3000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0689 - val_loss: 0.0925\n",
            "Epoch 281/3000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0693 - val_loss: 0.0924\n",
            "Epoch 282/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0709 - val_loss: 0.0917\n",
            "Epoch 283/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0692 - val_loss: 0.0918\n",
            "Epoch 284/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0706 - val_loss: 0.0919\n",
            "Epoch 285/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0702 - val_loss: 0.0919\n",
            "Epoch 286/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0685 - val_loss: 0.0926\n",
            "Epoch 287/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0695 - val_loss: 0.0928\n",
            "Epoch 288/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0685 - val_loss: 0.0931\n",
            "Epoch 289/3000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0696 - val_loss: 0.0930\n",
            "Epoch 290/3000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0702 - val_loss: 0.0924\n",
            "Epoch 291/3000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.0690 - val_loss: 0.0921\n",
            "Epoch 292/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0684 - val_loss: 0.0921\n",
            "Epoch 293/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0684 - val_loss: 0.0919\n",
            "Epoch 294/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0703 - val_loss: 0.0925\n",
            "Epoch 295/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0679 - val_loss: 0.0921\n",
            "Epoch 296/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0697 - val_loss: 0.0917\n",
            "Epoch 297/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0693 - val_loss: 0.0919\n",
            "Epoch 298/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0696 - val_loss: 0.0922\n",
            "Epoch 299/3000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0681 - val_loss: 0.0929\n",
            "Epoch 300/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0693 - val_loss: 0.0929\n",
            "Epoch 301/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0676 - val_loss: 0.0925\n",
            "Epoch 302/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0693 - val_loss: 0.0924\n",
            "Epoch 303/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0697 - val_loss: 0.0920\n",
            "Epoch 304/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0680 - val_loss: 0.0919\n",
            "Epoch 305/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0695 - val_loss: 0.0925\n",
            "Epoch 306/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0701 - val_loss: 0.0923\n",
            "Epoch 307/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0684 - val_loss: 0.0925\n",
            "Epoch 308/3000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.0686 - val_loss: 0.0927\n",
            "Epoch 309/3000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0686 - val_loss: 0.0932\n",
            "Epoch 310/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0686 - val_loss: 0.0929\n",
            "Epoch 311/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0682 - val_loss: 0.0931\n",
            "Epoch 312/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0688 - val_loss: 0.0928\n",
            "Epoch 313/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0685 - val_loss: 0.0927\n",
            "Epoch 314/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0687 - val_loss: 0.0924\n",
            "Epoch 315/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0681 - val_loss: 0.0923\n",
            "Epoch 316/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0677 - val_loss: 0.0924\n",
            "Epoch 317/3000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0687 - val_loss: 0.0927\n",
            "Epoch 318/3000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0695 - val_loss: 0.0929\n",
            "Epoch 319/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0692 - val_loss: 0.0929\n",
            "Epoch 320/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0701 - val_loss: 0.0925\n",
            "Epoch 321/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0688 - val_loss: 0.0921\n",
            "Epoch 322/3000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0700 - val_loss: 0.0923\n",
            "Epoch 323/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0684 - val_loss: 0.0925\n",
            "Epoch 324/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0675 - val_loss: 0.0923\n",
            "Epoch 325/3000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0689 - val_loss: 0.0919\n",
            "Epoch 326/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0677 - val_loss: 0.0920\n",
            "Epoch 327/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0698 - val_loss: 0.0921\n",
            "Epoch 328/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0683 - val_loss: 0.0916\n",
            "Epoch 329/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0679 - val_loss: 0.0919\n",
            "Epoch 330/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0703 - val_loss: 0.0916\n",
            "Epoch 331/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0684 - val_loss: 0.0915\n",
            "Epoch 332/3000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0676 - val_loss: 0.0914\n",
            "Epoch 333/3000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0682 - val_loss: 0.0918\n",
            "Epoch 334/3000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0659 - val_loss: 0.0917\n",
            "Epoch 335/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0694 - val_loss: 0.0917\n",
            "Epoch 336/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0674 - val_loss: 0.0924\n",
            "Epoch 337/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0679 - val_loss: 0.0924\n",
            "Epoch 338/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0677 - val_loss: 0.0919\n",
            "Epoch 339/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0677 - val_loss: 0.0918\n",
            "Epoch 340/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0691 - val_loss: 0.0912\n",
            "Epoch 341/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0683 - val_loss: 0.0919\n",
            "Epoch 342/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0680 - val_loss: 0.0921\n",
            "Epoch 343/3000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0669 - val_loss: 0.0921\n",
            "Epoch 344/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0672 - val_loss: 0.0922\n",
            "Epoch 345/3000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0691 - val_loss: 0.0921\n",
            "Epoch 346/3000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0689 - val_loss: 0.0923\n",
            "Epoch 347/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0687 - val_loss: 0.0928\n",
            "Epoch 348/3000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0684 - val_loss: 0.0919\n",
            "Epoch 349/3000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0684 - val_loss: 0.0914\n",
            "Epoch 350/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0677 - val_loss: 0.0915\n",
            "Epoch 351/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0674 - val_loss: 0.0915\n",
            "Epoch 352/3000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0671 - val_loss: 0.0915\n",
            "Epoch 353/3000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0695 - val_loss: 0.0914\n",
            "Epoch 354/3000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0674 - val_loss: 0.0912\n",
            "Epoch 355/3000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0692 - val_loss: 0.0907\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f64d0491eb0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_tr, y_tr, validation_data=(X_te, y_te), epochs=3000, callbacks=[es_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "grGTlDxFHwof"
      },
      "outputs": [],
      "source": [
        "model.save(path_to_cp_dir('model_fund_classifier.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WLAQBvWtLWrm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LUEpZZICn3G",
        "outputId": "115bf950-4606-4e38-e6dc-b8b691bb296c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['rbf ventures' 'winter capital' 'emery capital'], y=фрии\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['inventure partners' 'flashpoint vc' 'фонд \"прообраз\"'], y=inventure partners\n",
            "Pred=['addventure' 'flashpoint vc' 'larix'], y=winter capital\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['inventure partners' 'flashpoint vc' 'фонд \"прообраз\"'], y=inventure partners\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['фрии' 'the untitled ventures' 'венчурный фонд нти'], y=фонд поддержки проектов нти\n",
            "Pred=['softline venture partners' 'венчурный фонд мтс' 'yellowrockets'], y=yellowrockets\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=leta capital\n",
            "Pred=['moscow seed fund' 'rbf ventures' 'dv capital'], y=moscow seed fund\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=starta ventures\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['baring vostok' 'эльбрус капитал' 'addventure'], y=altair capital\n",
            "Pred=['moscow seed fund' 'rbf ventures' 'dv capital'], y=moscow seed fund\n",
            "Pred=['digital evolution ventures' 'венчурный фонд нти' 'i2bf global ventures'], y=i2bf global ventures\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['winno moscow' 'rbf ventures' 'cabra vc'], y=winno moscow\n",
            "Pred=['sistema smarttech' 'венчурный фонд мтс' 'softline venture partners'], y=sistema smarttech\n",
            "Pred=['softline venture partners' 'венчурный фонд мтс' 'sistema smarttech'], y=softline venture partners\n",
            "Pred=['фрии' 'da vinci capital' 'leta capital'], y=дальневосточный фонд высоких технологий\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['pulsar vc' 'np capital' 'the untitled ventures'], y=pulsar vc\n",
            "Pred=['венчурный фонд нти' 'the untitled ventures'\n",
            " 'фонд поддержки проектов нти'], y=венчурный фонд нти\n",
            "Pred=['rbf ventures' 'winter capital' 'cabra vc'], y=rbf ventures\n",
            "Pred=['фрии' 'the untitled ventures' 'венчурный фонд нти'], y=фрии\n",
            "Pred=['digital evolution ventures' 'венчурный фонд нти' 'i2bf global ventures'], y=digital evolution ventures\n",
            "Pred=['baring vostok' 'flashpoint vc' 'addventure'], y=российский фонд прямых инвестиций\n",
            "Pred=['starta ventures' 'dv capital' 'фрии'], y=moscow seed fund\n",
            "Pred=['addventure' 'flashpoint vc' 'larix'], y=target global\n",
            "Pred=['moscow seed fund' 'rbf ventures' 'dv capital'], y=фонд содействия инновациям\n",
            "Pred=['фрии' 'the untitled ventures' 'leta capital'], y=фрии\n",
            "Pred=['фрии' 'the untitled ventures' 'венчурный фонд мтс'], y=фрии\n",
            "Pred=['фрии' 'венчурный фонд мтс' 'the untitled ventures'], y=фонд поддержки проектов нти\n",
            "Pred=['addventure' 'flashpoint vc' 'эльбрус капитал'], y=addventure\n",
            "Pred=['winno moscow' 'rbf ventures' 'cabra vc'], y=moscow seed fund\n",
            "Pred=['starta ventures' 'фонд \"прообраз\"' 'imi.vc'], y=starta ventures\n"
          ]
        }
      ],
      "source": [
        "from numpy import linalg as LA\n",
        "\n",
        "preds = model.predict(X_te)\n",
        "for i in range(len(preds)):\n",
        "    idx_sorted = np.argsort(np.apply_along_axis(LA.norm, 1, investors_space - preds[i], ord=2))\n",
        "    print(\"Pred={}, y={}\".format(investors_space_name[idx_sorted[:3]], fund_name_te[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HUsMdRnGqr7",
        "outputId": "56fc7ff1-67cd-4797-aef4-7f0c3d4ddf4d"
      },
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "def predict(company, services, answer_in):\n",
        "    company = company.rename(columns=lambda x: '{}__company'.format(x))\n",
        "    services = services.rename(columns=lambda x: '{}__investor'.format(x))\n",
        "    \n",
        "    X = load(path_to_data_dir('fund_classifier_preprocessor_X.joblib')).transform(np.array([company]))\n",
        "    services_space = load(path_to_data_dir('fund_classifier_preprocessor_Y.joblib')).transform(services)\n",
        "\n",
        "    proj = tf.keras.models.load_model('fund_classifier_model.h5').predict(X)[0]\n",
        "\n",
        "    idx_sorted = np.argsort(np.apply_along_axis(LA.norm, 1, services_space - proj, ord=2))\n",
        "\n",
        "    return answer_in[idx_sorted]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YhliQmmEoZi",
        "outputId": "7f636c69-19fb-49c4-d4be-bde93551ab69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def train(train_data, val_data):\n",
        "    pre_X = load(path_to_data_dir('fund_classifier_preprocessor_X.joblib'))\n",
        "    pre_Y = load(path_to_data_dir('fund_classifier_preprocessor_Y.joblib')).transform(train_data)\n",
        "\n",
        "    X_tr = pre_X.transform(train_data)\n",
        "    y_tr = pre_Y.transform(train_data)\n",
        "\n",
        "    X_te = pre_X.transform(val_data)\n",
        "    y_te = pre_Y.transform(val_data)\n",
        "\n",
        "    es_cb = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', min_delta=0.001, patience=10, verbose=0,\n",
        "        mode='auto', baseline=None, restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    model = tf.keras.models.load_model(path_to_data_dir('fund_classifier_model.h5'))\n",
        "    \n",
        "    model.fit(X_tr, y_tr, validation_data=(X_te, y_te), epochs=100, callbacks=[es_cb])\n",
        "\n",
        "    model.save(path_to_data_dir('fund_classifier_model.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evVSsMW8GOU2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "investor_classifier.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3ee233417952d695300db9ba46d8204d5b7b437c2396c86d9acd29e8d7cf9c2e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
